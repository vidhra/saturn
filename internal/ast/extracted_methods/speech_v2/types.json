{
  "/Users/prashanthvarma/Saturn/internal/ast/google-cloud-python/packages/google-cloud-speech/google/cloud/speech_v2/types/cloud_speech.py": [
    {
      "type": "function",
      "name": "CreateRecognizerRequest",
      "description": "Request message for the\n[CreateRecognizer][google.cloud.speech.v2.Speech.CreateRecognizer]\nmethod.\n\nAttributes:\n    recognizer (google.cloud.speech_v2.types.Recognizer):\n        Required. The Recognizer to create.\n    validate_only (bool):\n        If set, validate the request and preview the\n        Recognizer, but do not actually create it.\n    recognizer_id (str):\n        The ID to use for the Recognizer, which will become the\n        final component of the Recognizer's resource name.\n\n        This value should be 4-63 characters, and valid characters\n        are /[a-z][0-9]-/.\n    parent (str):\n        Required. The project and location where this Recognizer\n        will be created. The expected format is\n        ``projects/{project}/locations/{location}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "recognizer": {
            "description": "Required. The Recognizer to create.",
            "reference": "google.cloud.speech_v2.types.Recognizer",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the Recognizer. Format: ``projects/{project}/locations/{location}/recognizers/{recognizer}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the Recognizer.",
                  "type": "string"
                },
                "display_name": {
                  "description": "User-settable, human-readable name for the Recognizer. Must be 63 characters or less.",
                  "type": "string"
                },
                "model": {
                  "description": "Optional. This field is now deprecated. Prefer the [``model``][google.cloud.speech.v2.RecognitionConfig.model] field in the [``RecognitionConfig``][google.cloud.speech.v2.RecognitionConfig] message.  Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                  "type": "string"
                },
                "language_codes": {
                  "description": "Optional. This field is now deprecated. Prefer the [``language_codes``][google.cloud.speech.v2.RecognitionConfig.language_codes] field in the [``RecognitionConfig``][google.cloud.speech.v2.RecognitionConfig] message.  The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag.  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio. When you create or update a Recognizer, these values are stored in normalized BCP-47 form. For example, \"en-us\" is stored as \"en-US\".",
                  "type": "array",
                  "items": {
                    "type": "string"
                  }
                },
                "default_recognition_config": {
                  "description": "Default configuration to use for requests with this Recognizer. This can be overwritten by inline configuration in the [RecognizeRequest.config][google.cloud.speech.v2.RecognizeRequest.config] field.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.RecognitionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "auto_decoding_config": {
                        "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      },
                      "explicit_decoding_config": {
                        "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "encoding": {
                              "description": "Required. Encoding of the audio data sent for recognition.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                            },
                            "sample_rate_hertz": {
                              "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                              "type": "integer"
                            },
                            "audio_channel_count": {
                              "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                              "type": "integer"
                            }
                          },
                          "required": [
                            "encoding"
                          ]
                        }
                      },
                      "model": {
                        "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                        "type": "string"
                      },
                      "language_codes": {
                        "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                        "type": "array",
                        "items": {
                          "type": "string"
                        }
                      },
                      "features": {
                        "description": "Speech recognition features to enable.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "profanity_filter": {
                              "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                              "type": "boolean"
                            },
                            "enable_word_time_offsets": {
                              "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_word_confidence": {
                              "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_automatic_punctuation": {
                              "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                              "type": "boolean"
                            },
                            "enable_spoken_punctuation": {
                              "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                              "type": "boolean"
                            },
                            "enable_spoken_emojis": {
                              "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                              "type": "boolean"
                            },
                            "multi_channel_mode": {
                              "description": "Mode for recognizing multi-channel audio.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                            },
                            "diarization_config": {
                              "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                              "resolved_schema": {
                                "type": "object",
                                "properties": {
                                  "min_speaker_count": {
                                    "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                                    "type": "integer"
                                  },
                                  "max_speaker_count": {
                                    "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                                    "type": "integer"
                                  }
                                },
                                "required": [
                                  "min_speaker_count",
                                  "max_speaker_count"
                                ]
                              }
                            },
                            "max_alternatives": {
                              "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                              "type": "integer"
                            }
                          }
                        }
                      },
                      "adaptation": {
                        "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "phrase_sets": {
                              "description": "A list of inline or referenced PhraseSets.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "phrase_set": {
                                      "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                      "type": "string"
                                    },
                                    "inline_phrase_set": {
                                      "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.PhraseSet",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "name": {
                                            "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                            "type": "string"
                                          },
                                          "uid": {
                                            "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                            "type": "string"
                                          },
                                          "phrases": {
                                            "description": "A list of word and phrases.",
                                            "type": "array",
                                            "items": {
                                              "type": "object",
                                              "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                              "resolved_schema": {
                                                "type": "object",
                                                "properties": {
                                                  "text": {
                                                    "description": "Required. Text input which can be used for prompt or banned phrases.",
                                                    "type": "string"
                                                  },
                                                  "language_code": {
                                                    "description": "Required. Language code of the phrase.",
                                                    "type": "string"
                                                  }
                                                },
                                                "required": [
                                                  "text",
                                                  "language_code"
                                                ]
                                              }
                                            }
                                          },
                                          "boost": {
                                            "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                            "type": "number"
                                          },
                                          "display_name": {
                                            "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                            "type": "string"
                                          },
                                          "state": {
                                            "description": "Output only. The PhraseSet lifecycle state.",
                                            "type": "object",
                                            "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                          },
                                          "create_time": {
                                            "description": "Output only. Creation time.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "update_time": {
                                            "description": "Output only. The most recent time this resource was modified.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "delete_time": {
                                            "description": "Output only. The time at which this resource was requested for deletion.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "expire_time": {
                                            "description": "Output only. The time at which this resource will be purged.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "annotations": {
                                            "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                            "type": "object",
                                            "additionalProperties": {
                                              "type": "string"
                                            }
                                          },
                                          "etag": {
                                            "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                            "type": "string"
                                          },
                                          "reconciling": {
                                            "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                            "type": "boolean"
                                          },
                                          "kms_key_name": {
                                            "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                            "type": "string"
                                          },
                                          "kms_key_version_name": {
                                            "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            },
                            "custom_classes": {
                              "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.CustomClass",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                      "type": "string"
                                    },
                                    "uid": {
                                      "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                      "type": "string"
                                    },
                                    "display_name": {
                                      "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                      "type": "string"
                                    },
                                    "items": {
                                      "description": "A collection of class items.",
                                      "type": "array",
                                      "items": {
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "value": {
                                              "description": "The class item's value.",
                                              "type": "string"
                                            }
                                          }
                                        }
                                      }
                                    },
                                    "state": {
                                      "description": "Output only. The CustomClass lifecycle state.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.CustomClass.State"
                                    },
                                    "create_time": {
                                      "description": "Output only. Creation time.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "update_time": {
                                      "description": "Output only. The most recent time this resource was modified.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "delete_time": {
                                      "description": "Output only. The time at which this resource was requested for deletion.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "expire_time": {
                                      "description": "Output only. The time at which this resource will be purged.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "annotations": {
                                      "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                      "type": "object",
                                      "additionalProperties": {
                                        "type": "string"
                                      }
                                    },
                                    "etag": {
                                      "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                      "type": "string"
                                    },
                                    "reconciling": {
                                      "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                      "type": "boolean"
                                    },
                                    "kms_key_name": {
                                      "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                      "type": "string"
                                    },
                                    "kms_key_version_name": {
                                      "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "transcript_normalization": {
                        "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "entries": {
                              "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "role": {
                                      "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                      "type": "string"
                                    },
                                    "group_email": {
                                      "description": "Grants access to a group identified by an email address.",
                                      "type": "string"
                                    },
                                    "user_email": {
                                      "description": "Grants access to a user identified by an email address.",
                                      "type": "string"
                                    },
                                    "domain": {
                                      "description": "Grants access to all members of a domain.",
                                      "type": "string"
                                    },
                                    "special_group": {
                                      "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                      "type": "string"
                                    },
                                    "view_name": {
                                      "description": "Grants access to a BigQuery View.",
                                      "type": "object",
                                      "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "project_id": {
                                            "description": "The project ID.",
                                            "type": "string"
                                          },
                                          "dataset_id": {
                                            "description": "The dataset ID within the project.",
                                            "type": "string"
                                          },
                                          "table_id": {
                                            "description": "The table ID of the table within the dataset.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "translation_config": {
                        "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranslationConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "target_language": {
                              "description": "Required. The language code to translate to.",
                              "type": "string"
                            }
                          },
                          "required": [
                            "target_language"
                          ]
                        }
                      }
                    }
                  }
                },
                "annotations": {
                  "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "state": {
                  "description": "Output only. The Recognizer lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.Recognizer.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this Recognizer was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this Recognizer was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this Recognizer will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this Recognizer is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the Recognizer is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the Recognizer is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "validate_only": {
            "description": "If set, validate the request and preview the Recognizer, but do not actually create it.",
            "type": "boolean"
          },
          "recognizer_id": {
            "description": "The ID to use for the Recognizer, which will become the final component of the Recognizer's resource name.  This value should be 4-63 characters, and valid characters are /[a-z][0-9]-/.",
            "type": "string"
          },
          "parent": {
            "description": "Required. The project and location where this Recognizer will be created. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          }
        },
        "required": [
          "recognizer",
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "ListRecognizersRequest",
      "description": "Request message for the\n[ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers]\nmethod.\n\nAttributes:\n    parent (str):\n        Required. The project and location of Recognizers to list.\n        The expected format is\n        ``projects/{project}/locations/{location}``.\n    page_size (int):\n        The maximum number of Recognizers to return.\n        The service may return fewer than this value. If\n        unspecified, at most 5 Recognizers will be\n        returned. The maximum value is 100; values above\n        100 will be coerced to 100.\n    page_token (str):\n        A page token, received from a previous\n        [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers]\n        call. Provide this to retrieve the subsequent page.\n\n        When paginating, all other parameters provided to\n        [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers]\n        must match the call that provided the page token.\n    show_deleted (bool):\n        Whether, or not, to show resources that have\n",
      "parameters": {
        "type": "object",
        "properties": {
          "parent": {
            "description": "Required. The project and location of Recognizers to list. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          },
          "page_size": {
            "description": "The maximum number of Recognizers to return. The service may return fewer than this value. If unspecified, at most 5 Recognizers will be returned. The maximum value is 100; values above 100 will be coerced to 100.",
            "type": "integer"
          },
          "page_token": {
            "description": "A page token, received from a previous [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] call. Provide this to retrieve the subsequent page.  When paginating, all other parameters provided to [ListRecognizers][google.cloud.speech.v2.Speech.ListRecognizers] must match the call that provided the page token.",
            "type": "string"
          },
          "show_deleted": {
            "description": "Whether, or not, to show resources that have been deleted.",
            "type": "boolean"
          }
        },
        "required": [
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "GetRecognizerRequest",
      "description": "Request message for the\n[GetRecognizer][google.cloud.speech.v2.Speech.GetRecognizer] method.\n\nAttributes:\n    name (str):\n        Required. The name of the Recognizer to retrieve. The\n        expected format is\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the Recognizer to retrieve. The expected format is ``projects/{project}/locations/{location}/recognizers/{recognizer}``.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UpdateRecognizerRequest",
      "description": "Request message for the\n[UpdateRecognizer][google.cloud.speech.v2.Speech.UpdateRecognizer]\nmethod.\n\nAttributes:\n    recognizer (google.cloud.speech_v2.types.Recognizer):\n        Required. The Recognizer to update.\n\n        The Recognizer's ``name`` field is used to identify the\n        Recognizer to update. Format:\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``.\n    update_mask (google.protobuf.field_mask_pb2.FieldMask):\n        The list of fields to update. If empty, all non-default\n        valued fields are considered for update. Use ``*`` to update\n        the entire Recognizer resource.\n    validate_only (bool):\n        If set, validate the request and preview the\n        updated Recognizer, but do not actually update\n        it.",
      "parameters": {
        "type": "object",
        "properties": {
          "recognizer": {
            "description": "Required. The Recognizer to update.  The Recognizer's ``name`` field is used to identify the Recognizer to update. Format: ``projects/{project}/locations/{location}/recognizers/{recognizer}``.",
            "reference": "google.cloud.speech_v2.types.Recognizer",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the Recognizer. Format: ``projects/{project}/locations/{location}/recognizers/{recognizer}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the Recognizer.",
                  "type": "string"
                },
                "display_name": {
                  "description": "User-settable, human-readable name for the Recognizer. Must be 63 characters or less.",
                  "type": "string"
                },
                "model": {
                  "description": "Optional. This field is now deprecated. Prefer the [``model``][google.cloud.speech.v2.RecognitionConfig.model] field in the [``RecognitionConfig``][google.cloud.speech.v2.RecognitionConfig] message.  Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                  "type": "string"
                },
                "language_codes": {
                  "description": "Optional. This field is now deprecated. Prefer the [``language_codes``][google.cloud.speech.v2.RecognitionConfig.language_codes] field in the [``RecognitionConfig``][google.cloud.speech.v2.RecognitionConfig] message.  The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag.  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio. When you create or update a Recognizer, these values are stored in normalized BCP-47 form. For example, \"en-us\" is stored as \"en-US\".",
                  "type": "array",
                  "items": {
                    "type": "string"
                  }
                },
                "default_recognition_config": {
                  "description": "Default configuration to use for requests with this Recognizer. This can be overwritten by inline configuration in the [RecognizeRequest.config][google.cloud.speech.v2.RecognizeRequest.config] field.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.RecognitionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "auto_decoding_config": {
                        "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      },
                      "explicit_decoding_config": {
                        "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "encoding": {
                              "description": "Required. Encoding of the audio data sent for recognition.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                            },
                            "sample_rate_hertz": {
                              "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                              "type": "integer"
                            },
                            "audio_channel_count": {
                              "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                              "type": "integer"
                            }
                          },
                          "required": [
                            "encoding"
                          ]
                        }
                      },
                      "model": {
                        "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                        "type": "string"
                      },
                      "language_codes": {
                        "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                        "type": "array",
                        "items": {
                          "type": "string"
                        }
                      },
                      "features": {
                        "description": "Speech recognition features to enable.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "profanity_filter": {
                              "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                              "type": "boolean"
                            },
                            "enable_word_time_offsets": {
                              "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_word_confidence": {
                              "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_automatic_punctuation": {
                              "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                              "type": "boolean"
                            },
                            "enable_spoken_punctuation": {
                              "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                              "type": "boolean"
                            },
                            "enable_spoken_emojis": {
                              "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                              "type": "boolean"
                            },
                            "multi_channel_mode": {
                              "description": "Mode for recognizing multi-channel audio.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                            },
                            "diarization_config": {
                              "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                              "resolved_schema": {
                                "type": "object",
                                "properties": {
                                  "min_speaker_count": {
                                    "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                                    "type": "integer"
                                  },
                                  "max_speaker_count": {
                                    "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                                    "type": "integer"
                                  }
                                },
                                "required": [
                                  "min_speaker_count",
                                  "max_speaker_count"
                                ]
                              }
                            },
                            "max_alternatives": {
                              "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                              "type": "integer"
                            }
                          }
                        }
                      },
                      "adaptation": {
                        "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "phrase_sets": {
                              "description": "A list of inline or referenced PhraseSets.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "phrase_set": {
                                      "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                      "type": "string"
                                    },
                                    "inline_phrase_set": {
                                      "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.PhraseSet",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "name": {
                                            "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                            "type": "string"
                                          },
                                          "uid": {
                                            "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                            "type": "string"
                                          },
                                          "phrases": {
                                            "description": "A list of word and phrases.",
                                            "type": "array",
                                            "items": {
                                              "type": "object",
                                              "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                              "resolved_schema": {
                                                "type": "object",
                                                "properties": {
                                                  "text": {
                                                    "description": "Required. Text input which can be used for prompt or banned phrases.",
                                                    "type": "string"
                                                  },
                                                  "language_code": {
                                                    "description": "Required. Language code of the phrase.",
                                                    "type": "string"
                                                  }
                                                },
                                                "required": [
                                                  "text",
                                                  "language_code"
                                                ]
                                              }
                                            }
                                          },
                                          "boost": {
                                            "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                            "type": "number"
                                          },
                                          "display_name": {
                                            "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                            "type": "string"
                                          },
                                          "state": {
                                            "description": "Output only. The PhraseSet lifecycle state.",
                                            "type": "object",
                                            "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                          },
                                          "create_time": {
                                            "description": "Output only. Creation time.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "update_time": {
                                            "description": "Output only. The most recent time this resource was modified.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "delete_time": {
                                            "description": "Output only. The time at which this resource was requested for deletion.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "expire_time": {
                                            "description": "Output only. The time at which this resource will be purged.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "annotations": {
                                            "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                            "type": "object",
                                            "additionalProperties": {
                                              "type": "string"
                                            }
                                          },
                                          "etag": {
                                            "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                            "type": "string"
                                          },
                                          "reconciling": {
                                            "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                            "type": "boolean"
                                          },
                                          "kms_key_name": {
                                            "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                            "type": "string"
                                          },
                                          "kms_key_version_name": {
                                            "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            },
                            "custom_classes": {
                              "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.CustomClass",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                      "type": "string"
                                    },
                                    "uid": {
                                      "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                      "type": "string"
                                    },
                                    "display_name": {
                                      "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                      "type": "string"
                                    },
                                    "items": {
                                      "description": "A collection of class items.",
                                      "type": "array",
                                      "items": {
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "value": {
                                              "description": "The class item's value.",
                                              "type": "string"
                                            }
                                          }
                                        }
                                      }
                                    },
                                    "state": {
                                      "description": "Output only. The CustomClass lifecycle state.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.CustomClass.State"
                                    },
                                    "create_time": {
                                      "description": "Output only. Creation time.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "update_time": {
                                      "description": "Output only. The most recent time this resource was modified.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "delete_time": {
                                      "description": "Output only. The time at which this resource was requested for deletion.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "expire_time": {
                                      "description": "Output only. The time at which this resource will be purged.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "annotations": {
                                      "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                      "type": "object",
                                      "additionalProperties": {
                                        "type": "string"
                                      }
                                    },
                                    "etag": {
                                      "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                      "type": "string"
                                    },
                                    "reconciling": {
                                      "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                      "type": "boolean"
                                    },
                                    "kms_key_name": {
                                      "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                      "type": "string"
                                    },
                                    "kms_key_version_name": {
                                      "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "transcript_normalization": {
                        "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "entries": {
                              "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "role": {
                                      "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                      "type": "string"
                                    },
                                    "group_email": {
                                      "description": "Grants access to a group identified by an email address.",
                                      "type": "string"
                                    },
                                    "user_email": {
                                      "description": "Grants access to a user identified by an email address.",
                                      "type": "string"
                                    },
                                    "domain": {
                                      "description": "Grants access to all members of a domain.",
                                      "type": "string"
                                    },
                                    "special_group": {
                                      "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                      "type": "string"
                                    },
                                    "view_name": {
                                      "description": "Grants access to a BigQuery View.",
                                      "type": "object",
                                      "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "project_id": {
                                            "description": "The project ID.",
                                            "type": "string"
                                          },
                                          "dataset_id": {
                                            "description": "The dataset ID within the project.",
                                            "type": "string"
                                          },
                                          "table_id": {
                                            "description": "The table ID of the table within the dataset.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "translation_config": {
                        "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranslationConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "target_language": {
                              "description": "Required. The language code to translate to.",
                              "type": "string"
                            }
                          },
                          "required": [
                            "target_language"
                          ]
                        }
                      }
                    }
                  }
                },
                "annotations": {
                  "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "state": {
                  "description": "Output only. The Recognizer lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.Recognizer.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this Recognizer was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this Recognizer was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this Recognizer will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this Recognizer is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the Recognizer is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the Recognizer is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "update_mask": {
            "description": "The list of fields to update. If empty, all non-default valued fields are considered for update. Use ``*`` to update the entire Recognizer resource.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the updated Recognizer, but do not actually update it.",
            "type": "boolean"
          }
        },
        "required": [
          "recognizer"
        ]
      }
    },
    {
      "type": "function",
      "name": "DeleteRecognizerRequest",
      "description": "Request message for the\n[DeleteRecognizer][google.cloud.speech.v2.Speech.DeleteRecognizer]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the Recognizer to delete. Format:\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        deleted Recognizer, but do not actually delete\n        it.\n    allow_missing (bool):\n        If set to true, and the Recognizer is not\n        found, the request will succeed and  be a no-op\n        (no Operation is recorded in this case).\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the Recognizer to delete. Format: ``projects/{project}/locations/{location}/recognizers/{recognizer}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the deleted Recognizer, but do not actually delete it.",
            "type": "boolean"
          },
          "allow_missing": {
            "description": "If set to true, and the Recognizer is not found, the request will succeed and  be a no-op (no Operation is recorded in this case).",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UndeleteRecognizerRequest",
      "description": "Request message for the\n[UndeleteRecognizer][google.cloud.speech.v2.Speech.UndeleteRecognizer]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the Recognizer to undelete. Format:\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        undeleted Recognizer, but do not actually\n        undelete it.\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the Recognizer to undelete. Format: ``projects/{project}/locations/{location}/recognizers/{recognizer}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the undeleted Recognizer, but do not actually undelete it.",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "RecognizeRequest",
      "description": "Request message for the\n[Recognize][google.cloud.speech.v2.Speech.Recognize] method. Either\n``content`` or ``uri`` must be supplied. Supplying both or neither\nreturns [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. See\n`content\nlimits <https://cloud.google.com/speech-to-text/quotas#content>`__.\n\nThis message has `oneof`_ fields (mutually exclusive fields).\nFor each oneof, at most one member field can be set at the same time.\nSetting any member of the oneof automatically clears all other\nmembers.\n\n.. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields\n\nAttributes:\n    recognizer (str):\n        Required. The name of the Recognizer to use during\n        recognition. The expected format is\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``.\n        The {recognizer} segment may be set to ``_`` to use an empty\n        implicit Recognizer.\n    config (google.cloud.speech_v2.types.RecognitionConfig):\n        Features and audio metadat",
      "parameters": {
        "type": "object",
        "properties": {
          "recognizer": {
            "description": "Required. The name of the Recognizer to use during recognition. The expected format is ``projects/{project}/locations/{location}/recognizers/{recognizer}``. The {recognizer} segment may be set to ``_`` to use an empty implicit Recognizer.",
            "type": "string"
          },
          "config": {
            "description": "Features and audio metadata to use for the Automatic Speech Recognition. This field in combination with the [config_mask][google.cloud.speech.v2.RecognizeRequest.config_mask] field can be used to override parts of the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the Recognizer resource.",
            "reference": "google.cloud.speech_v2.types.RecognitionConfig",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "auto_decoding_config": {
                  "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "explicit_decoding_config": {
                  "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "encoding": {
                        "description": "Required. Encoding of the audio data sent for recognition.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                      },
                      "sample_rate_hertz": {
                        "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                        "type": "integer"
                      },
                      "audio_channel_count": {
                        "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                        "type": "integer"
                      }
                    },
                    "required": [
                      "encoding"
                    ]
                  }
                },
                "model": {
                  "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                  "type": "string"
                },
                "language_codes": {
                  "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                  "type": "array",
                  "items": {
                    "type": "string"
                  }
                },
                "features": {
                  "description": "Speech recognition features to enable.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "profanity_filter": {
                        "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                        "type": "boolean"
                      },
                      "enable_word_time_offsets": {
                        "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                        "type": "boolean"
                      },
                      "enable_word_confidence": {
                        "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                        "type": "boolean"
                      },
                      "enable_automatic_punctuation": {
                        "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                        "type": "boolean"
                      },
                      "enable_spoken_punctuation": {
                        "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                        "type": "boolean"
                      },
                      "enable_spoken_emojis": {
                        "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                        "type": "boolean"
                      },
                      "multi_channel_mode": {
                        "description": "Mode for recognizing multi-channel audio.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                      },
                      "diarization_config": {
                        "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "min_speaker_count": {
                              "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                              "type": "integer"
                            },
                            "max_speaker_count": {
                              "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                              "type": "integer"
                            }
                          },
                          "required": [
                            "min_speaker_count",
                            "max_speaker_count"
                          ]
                        }
                      },
                      "max_alternatives": {
                        "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                        "type": "integer"
                      }
                    }
                  }
                },
                "adaptation": {
                  "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "phrase_sets": {
                        "description": "A list of inline or referenced PhraseSets.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "phrase_set": {
                                "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                "type": "string"
                              },
                              "inline_phrase_set": {
                                "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.PhraseSet",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                      "type": "string"
                                    },
                                    "uid": {
                                      "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                      "type": "string"
                                    },
                                    "phrases": {
                                      "description": "A list of word and phrases.",
                                      "type": "array",
                                      "items": {
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "text": {
                                              "description": "Required. Text input which can be used for prompt or banned phrases.",
                                              "type": "string"
                                            },
                                            "language_code": {
                                              "description": "Required. Language code of the phrase.",
                                              "type": "string"
                                            }
                                          },
                                          "required": [
                                            "text",
                                            "language_code"
                                          ]
                                        }
                                      }
                                    },
                                    "boost": {
                                      "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                      "type": "number"
                                    },
                                    "display_name": {
                                      "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                      "type": "string"
                                    },
                                    "state": {
                                      "description": "Output only. The PhraseSet lifecycle state.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                    },
                                    "create_time": {
                                      "description": "Output only. Creation time.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "update_time": {
                                      "description": "Output only. The most recent time this resource was modified.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "delete_time": {
                                      "description": "Output only. The time at which this resource was requested for deletion.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "expire_time": {
                                      "description": "Output only. The time at which this resource will be purged.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "annotations": {
                                      "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                      "type": "object",
                                      "additionalProperties": {
                                        "type": "string"
                                      }
                                    },
                                    "etag": {
                                      "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                      "type": "string"
                                    },
                                    "reconciling": {
                                      "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                      "type": "boolean"
                                    },
                                    "kms_key_name": {
                                      "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                      "type": "string"
                                    },
                                    "kms_key_version_name": {
                                      "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "custom_classes": {
                        "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.CustomClass",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "name": {
                                "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                "type": "string"
                              },
                              "uid": {
                                "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                "type": "string"
                              },
                              "display_name": {
                                "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                "type": "string"
                              },
                              "items": {
                                "description": "A collection of class items.",
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                  "resolved_schema": {
                                    "type": "object",
                                    "properties": {
                                      "value": {
                                        "description": "The class item's value.",
                                        "type": "string"
                                      }
                                    }
                                  }
                                }
                              },
                              "state": {
                                "description": "Output only. The CustomClass lifecycle state.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.CustomClass.State"
                              },
                              "create_time": {
                                "description": "Output only. Creation time.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "update_time": {
                                "description": "Output only. The most recent time this resource was modified.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "delete_time": {
                                "description": "Output only. The time at which this resource was requested for deletion.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "expire_time": {
                                "description": "Output only. The time at which this resource will be purged.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "annotations": {
                                "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                "type": "object",
                                "additionalProperties": {
                                  "type": "string"
                                }
                              },
                              "etag": {
                                "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                "type": "string"
                              },
                              "reconciling": {
                                "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                "type": "boolean"
                              },
                              "kms_key_name": {
                                "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                "type": "string"
                              },
                              "kms_key_version_name": {
                                "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                "type": "string"
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "transcript_normalization": {
                  "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "entries": {
                        "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "role": {
                                "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                "type": "string"
                              },
                              "group_email": {
                                "description": "Grants access to a group identified by an email address.",
                                "type": "string"
                              },
                              "user_email": {
                                "description": "Grants access to a user identified by an email address.",
                                "type": "string"
                              },
                              "domain": {
                                "description": "Grants access to all members of a domain.",
                                "type": "string"
                              },
                              "special_group": {
                                "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                "type": "string"
                              },
                              "view_name": {
                                "description": "Grants access to a BigQuery View.",
                                "type": "object",
                                "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "project_id": {
                                      "description": "The project ID.",
                                      "type": "string"
                                    },
                                    "dataset_id": {
                                      "description": "The dataset ID within the project.",
                                      "type": "string"
                                    },
                                    "table_id": {
                                      "description": "The table ID of the table within the dataset.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "translation_config": {
                  "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.TranslationConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "target_language": {
                        "description": "Required. The language code to translate to.",
                        "type": "string"
                      }
                    },
                    "required": [
                      "target_language"
                    ]
                  }
                }
              }
            }
          },
          "config_mask": {
            "description": "The list of fields in [config][google.cloud.speech.v2.RecognizeRequest.config] that override the values in the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the recognizer during this recognition request. If no mask is provided, all non-default valued fields in [config][google.cloud.speech.v2.RecognizeRequest.config] override the values in the recognizer for this recognition request. If a mask is provided, only the fields listed in the mask override the config in the recognizer for this recognition request. If a wildcard (``*``) is provided, [config][google.cloud.speech.v2.RecognizeRequest.config] completely overrides and replaces the config in the recognizer for this recognition request.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          },
          "content": {
            "description": "The audio data bytes encoded as specified in [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. As with all bytes fields, proto buffers use a pure binary representation, whereas JSON representations use base64.  This field is a member of `oneof`_ ``audio_source``.",
            "type": "object",
            "reference": "bytes"
          },
          "uri": {
            "description": "URI that points to a file that contains audio data bytes as specified in [RecognitionConfig][google.cloud.speech.v2.RecognitionConfig]. The file must not be compressed (for example, gzip). Currently, only Google Cloud Storage URIs are supported, which must be specified in the following format: ``gs://bucket_name/object_name`` (other URI formats return [INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see `Request URIs <https://cloud.google.com/storage/docs/reference-uris>`__.  This field is a member of `oneof`_ ``audio_source``.",
            "type": "string"
          }
        },
        "required": [
          "recognizer"
        ]
      }
    },
    {
      "type": "function",
      "name": "StreamingRecognizeRequest",
      "description": "Request message for the\n[StreamingRecognize][google.cloud.speech.v2.Speech.StreamingRecognize]\nmethod. Multiple\n[StreamingRecognizeRequest][google.cloud.speech.v2.StreamingRecognizeRequest]\nmessages are sent in one call.\n\nIf the [Recognizer][google.cloud.speech.v2.Recognizer] referenced by\n[recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer]\ncontains a fully specified request configuration then the stream may\nonly contain messages with only\n[audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.\n\nOtherwise the first message must contain a\n[recognizer][google.cloud.speech.v2.StreamingRecognizeRequest.recognizer]\nand a\n[streaming_config][google.cloud.speech.v2.StreamingRecognizeRequest.streaming_config]\nmessage that together fully specify the request configuration and\nmust not contain\n[audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio]. All\nsubsequent messages must only have\n[audio][google.cloud.speech.v2.StreamingRecognizeRequest.audio] set.\n\nThis message has `oneo",
      "parameters": {
        "type": "object",
        "properties": {
          "recognizer": {
            "description": "Required. The name of the Recognizer to use during recognition. The expected format is ``projects/{project}/locations/{location}/recognizers/{recognizer}``. The {recognizer} segment may be set to ``_`` to use an empty implicit Recognizer.",
            "type": "string"
          },
          "streaming_config": {
            "description": "StreamingRecognitionConfig to be used in this recognition attempt. If provided, it will override the default RecognitionConfig stored in the Recognizer.  This field is a member of `oneof`_ ``streaming_request``.",
            "reference": "google.cloud.speech_v2.types.StreamingRecognitionConfig",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "config": {
                  "description": "Required. Features and audio metadata to use for the Automatic Speech Recognition. This field in combination with the [config_mask][google.cloud.speech.v2.StreamingRecognitionConfig.config_mask] field can be used to override parts of the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the Recognizer resource.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.RecognitionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "auto_decoding_config": {
                        "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      },
                      "explicit_decoding_config": {
                        "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "encoding": {
                              "description": "Required. Encoding of the audio data sent for recognition.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                            },
                            "sample_rate_hertz": {
                              "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                              "type": "integer"
                            },
                            "audio_channel_count": {
                              "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                              "type": "integer"
                            }
                          },
                          "required": [
                            "encoding"
                          ]
                        }
                      },
                      "model": {
                        "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                        "type": "string"
                      },
                      "language_codes": {
                        "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                        "type": "array",
                        "items": {
                          "type": "string"
                        }
                      },
                      "features": {
                        "description": "Speech recognition features to enable.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "profanity_filter": {
                              "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                              "type": "boolean"
                            },
                            "enable_word_time_offsets": {
                              "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_word_confidence": {
                              "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                              "type": "boolean"
                            },
                            "enable_automatic_punctuation": {
                              "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                              "type": "boolean"
                            },
                            "enable_spoken_punctuation": {
                              "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                              "type": "boolean"
                            },
                            "enable_spoken_emojis": {
                              "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                              "type": "boolean"
                            },
                            "multi_channel_mode": {
                              "description": "Mode for recognizing multi-channel audio.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                            },
                            "diarization_config": {
                              "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                              "type": "object",
                              "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                              "resolved_schema": {
                                "type": "object",
                                "properties": {
                                  "min_speaker_count": {
                                    "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                                    "type": "integer"
                                  },
                                  "max_speaker_count": {
                                    "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                                    "type": "integer"
                                  }
                                },
                                "required": [
                                  "min_speaker_count",
                                  "max_speaker_count"
                                ]
                              }
                            },
                            "max_alternatives": {
                              "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                              "type": "integer"
                            }
                          }
                        }
                      },
                      "adaptation": {
                        "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "phrase_sets": {
                              "description": "A list of inline or referenced PhraseSets.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "phrase_set": {
                                      "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                      "type": "string"
                                    },
                                    "inline_phrase_set": {
                                      "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.PhraseSet",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "name": {
                                            "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                            "type": "string"
                                          },
                                          "uid": {
                                            "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                            "type": "string"
                                          },
                                          "phrases": {
                                            "description": "A list of word and phrases.",
                                            "type": "array",
                                            "items": {
                                              "type": "object",
                                              "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                              "resolved_schema": {
                                                "type": "object",
                                                "properties": {
                                                  "text": {
                                                    "description": "Required. Text input which can be used for prompt or banned phrases.",
                                                    "type": "string"
                                                  },
                                                  "language_code": {
                                                    "description": "Required. Language code of the phrase.",
                                                    "type": "string"
                                                  }
                                                },
                                                "required": [
                                                  "text",
                                                  "language_code"
                                                ]
                                              }
                                            }
                                          },
                                          "boost": {
                                            "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                            "type": "number"
                                          },
                                          "display_name": {
                                            "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                            "type": "string"
                                          },
                                          "state": {
                                            "description": "Output only. The PhraseSet lifecycle state.",
                                            "type": "object",
                                            "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                          },
                                          "create_time": {
                                            "description": "Output only. Creation time.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "update_time": {
                                            "description": "Output only. The most recent time this resource was modified.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "delete_time": {
                                            "description": "Output only. The time at which this resource was requested for deletion.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "expire_time": {
                                            "description": "Output only. The time at which this resource will be purged.",
                                            "type": "object",
                                            "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                          },
                                          "annotations": {
                                            "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                            "type": "object",
                                            "additionalProperties": {
                                              "type": "string"
                                            }
                                          },
                                          "etag": {
                                            "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                            "type": "string"
                                          },
                                          "reconciling": {
                                            "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                            "type": "boolean"
                                          },
                                          "kms_key_name": {
                                            "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                            "type": "string"
                                          },
                                          "kms_key_version_name": {
                                            "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            },
                            "custom_classes": {
                              "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.CustomClass",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                      "type": "string"
                                    },
                                    "uid": {
                                      "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                      "type": "string"
                                    },
                                    "display_name": {
                                      "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                      "type": "string"
                                    },
                                    "items": {
                                      "description": "A collection of class items.",
                                      "type": "array",
                                      "items": {
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "value": {
                                              "description": "The class item's value.",
                                              "type": "string"
                                            }
                                          }
                                        }
                                      }
                                    },
                                    "state": {
                                      "description": "Output only. The CustomClass lifecycle state.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.CustomClass.State"
                                    },
                                    "create_time": {
                                      "description": "Output only. Creation time.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "update_time": {
                                      "description": "Output only. The most recent time this resource was modified.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "delete_time": {
                                      "description": "Output only. The time at which this resource was requested for deletion.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "expire_time": {
                                      "description": "Output only. The time at which this resource will be purged.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "annotations": {
                                      "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                      "type": "object",
                                      "additionalProperties": {
                                        "type": "string"
                                      }
                                    },
                                    "etag": {
                                      "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                      "type": "string"
                                    },
                                    "reconciling": {
                                      "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                      "type": "boolean"
                                    },
                                    "kms_key_name": {
                                      "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                      "type": "string"
                                    },
                                    "kms_key_version_name": {
                                      "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "transcript_normalization": {
                        "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "entries": {
                              "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                              "type": "array",
                              "items": {
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "role": {
                                      "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                      "type": "string"
                                    },
                                    "group_email": {
                                      "description": "Grants access to a group identified by an email address.",
                                      "type": "string"
                                    },
                                    "user_email": {
                                      "description": "Grants access to a user identified by an email address.",
                                      "type": "string"
                                    },
                                    "domain": {
                                      "description": "Grants access to all members of a domain.",
                                      "type": "string"
                                    },
                                    "special_group": {
                                      "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                      "type": "string"
                                    },
                                    "view_name": {
                                      "description": "Grants access to a BigQuery View.",
                                      "type": "object",
                                      "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                      "resolved_schema": {
                                        "type": "object",
                                        "properties": {
                                          "project_id": {
                                            "description": "The project ID.",
                                            "type": "string"
                                          },
                                          "dataset_id": {
                                            "description": "The dataset ID within the project.",
                                            "type": "string"
                                          },
                                          "table_id": {
                                            "description": "The table ID of the table within the dataset.",
                                            "type": "string"
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "translation_config": {
                        "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.TranslationConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "target_language": {
                              "description": "Required. The language code to translate to.",
                              "type": "string"
                            }
                          },
                          "required": [
                            "target_language"
                          ]
                        }
                      }
                    }
                  }
                },
                "config_mask": {
                  "description": "The list of fields in [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] that override the values in the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the recognizer during this recognition request. If no mask is provided, all non-default valued fields in [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] override the values in the Recognizer for this recognition request. If a mask is provided, only the fields listed in the mask override the config in the Recognizer for this recognition request. If a wildcard (``*``) is provided, [config][google.cloud.speech.v2.StreamingRecognitionConfig.config] completely overrides and replaces the config in the recognizer for this recognition request.",
                  "type": "object",
                  "reference": "google.protobuf.field_mask_pb2.FieldMask"
                },
                "streaming_features": {
                  "description": "Speech recognition features to enable specific to streaming audio recognition requests.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.StreamingRecognitionFeatures",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "enable_voice_activity_events": {
                        "description": "If ``true``, responses with voice activity speech events will be returned as they are detected.",
                        "type": "boolean"
                      },
                      "interim_results": {
                        "description": "Whether or not to stream interim results to the client. If set to true, interim results will be streamed to the client. Otherwise, only the final response will be streamed back.",
                        "type": "boolean"
                      },
                      "voice_activity_timeout": {
                        "description": "If set, the server will automatically close the stream after the specified duration has elapsed after the last VOICE_ACTIVITY speech event has been sent. The field ``voice_activity_events`` must also be set to true.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.StreamingRecognitionFeatures.VoiceActivityTimeout",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "speech_start_timeout": {
                              "description": "Duration to timeout the stream if no speech begins. If this is set and no speech is detected in this duration at the start of the stream, the server will close the stream.",
                              "type": "object",
                              "reference": "google.protobuf.duration_pb2.Duration",
                              "resolved_schema": {
                                "type": "object",
                                "properties": {
                                  "nanos": {
                                    "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                    "type": "integer"
                                  },
                                  "seconds": {
                                    "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                    "type": "integer"
                                  }
                                }
                              }
                            },
                            "speech_end_timeout": {
                              "description": "Duration to timeout the stream after speech ends. If this is set and no speech is detected in this duration after speech was detected, the server will close the stream.",
                              "type": "object",
                              "reference": "google.protobuf.duration_pb2.Duration",
                              "resolved_schema": {
                                "type": "object",
                                "properties": {
                                  "nanos": {
                                    "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                    "type": "integer"
                                  },
                                  "seconds": {
                                    "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                    "type": "integer"
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              },
              "required": [
                "config"
              ]
            }
          },
          "audio": {
            "description": "Inline audio bytes to be Recognized. Maximum size for this field is 15 KB per request.  This field is a member of `oneof`_ ``streaming_request``.",
            "type": "object",
            "reference": "bytes"
          }
        },
        "required": [
          "recognizer"
        ]
      }
    },
    {
      "type": "function",
      "name": "BatchRecognizeRequest",
      "description": "Request message for the\n[BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize]\nmethod.\n\nAttributes:\n    recognizer (str):\n        Required. The name of the Recognizer to use during\n        recognition. The expected format is\n        ``projects/{project}/locations/{location}/recognizers/{recognizer}``.\n        The {recognizer} segment may be set to ``_`` to use an empty\n        implicit Recognizer.\n    config (google.cloud.speech_v2.types.RecognitionConfig):\n        Features and audio metadata to use for the Automatic Speech\n        Recognition. This field in combination with the\n        [config_mask][google.cloud.speech.v2.BatchRecognizeRequest.config_mask]\n        field can be used to override parts of the\n        [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config]\n        of the Recognizer resource.\n    config_mask (google.protobuf.field_mask_pb2.FieldMask):\n        The list of fields in\n        [config][google.cloud.speech.v2.BatchRecognizeRequest.config]\n    ",
      "parameters": {
        "type": "object",
        "properties": {
          "recognizer": {
            "description": "Required. The name of the Recognizer to use during recognition. The expected format is ``projects/{project}/locations/{location}/recognizers/{recognizer}``. The {recognizer} segment may be set to ``_`` to use an empty implicit Recognizer.",
            "type": "string"
          },
          "config": {
            "description": "Features and audio metadata to use for the Automatic Speech Recognition. This field in combination with the [config_mask][google.cloud.speech.v2.BatchRecognizeRequest.config_mask] field can be used to override parts of the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the Recognizer resource.",
            "reference": "google.cloud.speech_v2.types.RecognitionConfig",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "auto_decoding_config": {
                  "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "explicit_decoding_config": {
                  "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "encoding": {
                        "description": "Required. Encoding of the audio data sent for recognition.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                      },
                      "sample_rate_hertz": {
                        "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                        "type": "integer"
                      },
                      "audio_channel_count": {
                        "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                        "type": "integer"
                      }
                    },
                    "required": [
                      "encoding"
                    ]
                  }
                },
                "model": {
                  "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                  "type": "string"
                },
                "language_codes": {
                  "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                  "type": "array",
                  "items": {
                    "type": "string"
                  }
                },
                "features": {
                  "description": "Speech recognition features to enable.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "profanity_filter": {
                        "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                        "type": "boolean"
                      },
                      "enable_word_time_offsets": {
                        "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                        "type": "boolean"
                      },
                      "enable_word_confidence": {
                        "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                        "type": "boolean"
                      },
                      "enable_automatic_punctuation": {
                        "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                        "type": "boolean"
                      },
                      "enable_spoken_punctuation": {
                        "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                        "type": "boolean"
                      },
                      "enable_spoken_emojis": {
                        "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                        "type": "boolean"
                      },
                      "multi_channel_mode": {
                        "description": "Mode for recognizing multi-channel audio.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                      },
                      "diarization_config": {
                        "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "min_speaker_count": {
                              "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                              "type": "integer"
                            },
                            "max_speaker_count": {
                              "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                              "type": "integer"
                            }
                          },
                          "required": [
                            "min_speaker_count",
                            "max_speaker_count"
                          ]
                        }
                      },
                      "max_alternatives": {
                        "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                        "type": "integer"
                      }
                    }
                  }
                },
                "adaptation": {
                  "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "phrase_sets": {
                        "description": "A list of inline or referenced PhraseSets.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "phrase_set": {
                                "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                "type": "string"
                              },
                              "inline_phrase_set": {
                                "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.PhraseSet",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "name": {
                                      "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                      "type": "string"
                                    },
                                    "uid": {
                                      "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                      "type": "string"
                                    },
                                    "phrases": {
                                      "description": "A list of word and phrases.",
                                      "type": "array",
                                      "items": {
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "text": {
                                              "description": "Required. Text input which can be used for prompt or banned phrases.",
                                              "type": "string"
                                            },
                                            "language_code": {
                                              "description": "Required. Language code of the phrase.",
                                              "type": "string"
                                            }
                                          },
                                          "required": [
                                            "text",
                                            "language_code"
                                          ]
                                        }
                                      }
                                    },
                                    "boost": {
                                      "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                      "type": "number"
                                    },
                                    "display_name": {
                                      "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                      "type": "string"
                                    },
                                    "state": {
                                      "description": "Output only. The PhraseSet lifecycle state.",
                                      "type": "object",
                                      "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                    },
                                    "create_time": {
                                      "description": "Output only. Creation time.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "update_time": {
                                      "description": "Output only. The most recent time this resource was modified.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "delete_time": {
                                      "description": "Output only. The time at which this resource was requested for deletion.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "expire_time": {
                                      "description": "Output only. The time at which this resource will be purged.",
                                      "type": "object",
                                      "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                    },
                                    "annotations": {
                                      "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                      "type": "object",
                                      "additionalProperties": {
                                        "type": "string"
                                      }
                                    },
                                    "etag": {
                                      "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                      "type": "string"
                                    },
                                    "reconciling": {
                                      "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                      "type": "boolean"
                                    },
                                    "kms_key_name": {
                                      "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                      "type": "string"
                                    },
                                    "kms_key_version_name": {
                                      "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      },
                      "custom_classes": {
                        "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.CustomClass",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "name": {
                                "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                "type": "string"
                              },
                              "uid": {
                                "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                "type": "string"
                              },
                              "display_name": {
                                "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                "type": "string"
                              },
                              "items": {
                                "description": "A collection of class items.",
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                  "resolved_schema": {
                                    "type": "object",
                                    "properties": {
                                      "value": {
                                        "description": "The class item's value.",
                                        "type": "string"
                                      }
                                    }
                                  }
                                }
                              },
                              "state": {
                                "description": "Output only. The CustomClass lifecycle state.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.CustomClass.State"
                              },
                              "create_time": {
                                "description": "Output only. Creation time.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "update_time": {
                                "description": "Output only. The most recent time this resource was modified.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "delete_time": {
                                "description": "Output only. The time at which this resource was requested for deletion.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "expire_time": {
                                "description": "Output only. The time at which this resource will be purged.",
                                "type": "object",
                                "reference": "google.protobuf.timestamp_pb2.Timestamp"
                              },
                              "annotations": {
                                "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                "type": "object",
                                "additionalProperties": {
                                  "type": "string"
                                }
                              },
                              "etag": {
                                "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                "type": "string"
                              },
                              "reconciling": {
                                "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                "type": "boolean"
                              },
                              "kms_key_name": {
                                "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                "type": "string"
                              },
                              "kms_key_version_name": {
                                "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                "type": "string"
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "transcript_normalization": {
                  "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "entries": {
                        "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                        "type": "array",
                        "items": {
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "role": {
                                "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                "type": "string"
                              },
                              "group_email": {
                                "description": "Grants access to a group identified by an email address.",
                                "type": "string"
                              },
                              "user_email": {
                                "description": "Grants access to a user identified by an email address.",
                                "type": "string"
                              },
                              "domain": {
                                "description": "Grants access to all members of a domain.",
                                "type": "string"
                              },
                              "special_group": {
                                "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                "type": "string"
                              },
                              "view_name": {
                                "description": "Grants access to a BigQuery View.",
                                "type": "object",
                                "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "project_id": {
                                      "description": "The project ID.",
                                      "type": "string"
                                    },
                                    "dataset_id": {
                                      "description": "The dataset ID within the project.",
                                      "type": "string"
                                    },
                                    "table_id": {
                                      "description": "The table ID of the table within the dataset.",
                                      "type": "string"
                                    }
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "translation_config": {
                  "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.TranslationConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "target_language": {
                        "description": "Required. The language code to translate to.",
                        "type": "string"
                      }
                    },
                    "required": [
                      "target_language"
                    ]
                  }
                }
              }
            }
          },
          "config_mask": {
            "description": "The list of fields in [config][google.cloud.speech.v2.BatchRecognizeRequest.config] that override the values in the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the recognizer during this recognition request. If no mask is provided, all given fields in [config][google.cloud.speech.v2.BatchRecognizeRequest.config] override the values in the recognizer for this recognition request. If a mask is provided, only the fields listed in the mask override the config in the recognizer for this recognition request. If a wildcard (``*``) is provided, [config][google.cloud.speech.v2.BatchRecognizeRequest.config] completely overrides and replaces the config in the recognizer for this recognition request.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          },
          "files": {
            "description": "Audio files with file metadata for ASR. The maximum number of files allowed to be specified is 15.",
            "type": "array",
            "items": {
              "reference": "google.cloud.speech_v2.types.BatchRecognizeFileMetadata",
              "resolved_schema": {
                "type": "object",
                "properties": {
                  "uri": {
                    "description": "Cloud Storage URI for the audio file.  This field is a member of `oneof`_ ``audio_source``.",
                    "type": "string"
                  },
                  "config": {
                    "description": "Features and audio metadata to use for the Automatic Speech Recognition. This field in combination with the [config_mask][google.cloud.speech.v2.BatchRecognizeFileMetadata.config_mask] field can be used to override parts of the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the Recognizer resource as well as the [config][google.cloud.speech.v2.BatchRecognizeRequest.config] at the request level.",
                    "type": "object",
                    "reference": "google.cloud.speech_v2.types.RecognitionConfig",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "auto_decoding_config": {
                          "description": "Automatically detect decoding parameters. Preferred for supported formats.  This field is a member of `oneof`_ ``decoding_config``.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.AutoDetectDecodingConfig",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {}
                          }
                        },
                        "explicit_decoding_config": {
                          "description": "Explicitly specified decoding parameters. Required if using headerless PCM audio (linear16, mulaw, alaw).  This field is a member of `oneof`_ ``decoding_config``.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "encoding": {
                                "description": "Required. Encoding of the audio data sent for recognition.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.ExplicitDecodingConfig.AudioEncoding"
                              },
                              "sample_rate_hertz": {
                                "description": "Sample rate in Hertz of the audio data sent for recognition. Valid values are: 8000-48000. 16000 is optimal. For best results, set the sampling rate of the audio source to 16000 Hz. If that's not possible, use the native sample rate of the audio source (instead of re-sampling). Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.",
                                "type": "integer"
                              },
                              "audio_channel_count": {
                                "description": "Number of channels present in the audio data sent for recognition. Supported for the following encodings:  -  LINEAR16: Headerless 16-bit signed little-endian PCM samples.  -  MULAW: Headerless 8-bit companded mulaw samples.  -  ALAW: Headerless 8-bit companded alaw samples.  The maximum allowed value is 8.",
                                "type": "integer"
                              }
                            },
                            "required": [
                              "encoding"
                            ]
                          }
                        },
                        "model": {
                          "description": "Optional. Which model to use for recognition requests. Select the model best suited to your domain to get best results.  Guidance for choosing which model to use can be found in the `Transcription Models Documentation <https://cloud.google.com/speech-to-text/v2/docs/transcription-model>`__ and the models supported in each region can be found in the `Table Of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.",
                          "type": "string"
                        },
                        "language_codes": {
                          "description": "Optional. The language of the supplied audio as a `BCP-47 <https://www.rfc-editor.org/rfc/bcp/bcp47.txt>`__ language tag. Language tags are normalized to BCP-47 before they are used eg \"en-us\" becomes \"en-US\".  Supported languages for each model are listed in the `Table of Supported Models <https://cloud.google.com/speech-to-text/v2/docs/speech-to-text-supported-languages>`__.  If additional languages are provided, recognition result will contain recognition in the most likely language detected. The recognition result will include the language tag of the language detected in the audio.",
                          "type": "array",
                          "items": {
                            "type": "string"
                          }
                        },
                        "features": {
                          "description": "Speech recognition features to enable.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.RecognitionFeatures",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "profanity_filter": {
                                "description": "If set to ``true``, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, for instance, \"f***\". If set to ``false`` or omitted, profanities won't be filtered out.",
                                "type": "boolean"
                              },
                              "enable_word_time_offsets": {
                                "description": "If ``true``, the top result includes a list of words and the start and end time offsets (timestamps) for those words. If ``false``, no word-level time offset information is returned. The default is ``false``.",
                                "type": "boolean"
                              },
                              "enable_word_confidence": {
                                "description": "If ``true``, the top result includes a list of words and the confidence for those words. If ``false``, no word-level confidence information is returned. The default is ``false``.",
                                "type": "boolean"
                              },
                              "enable_automatic_punctuation": {
                                "description": "If ``true``, adds punctuation to recognition result hypotheses. This feature is only available in select languages. The default ``false`` value does not add punctuation to result hypotheses.",
                                "type": "boolean"
                              },
                              "enable_spoken_punctuation": {
                                "description": "The spoken punctuation behavior for the call. If ``true``, replaces spoken punctuation with the corresponding symbols in the request. For example, \"how are you question mark\" becomes \"how are you?\". See https://cloud.google.com/speech-to-text/docs/spoken-punctuation for support. If ``false``, spoken punctuation is not replaced.",
                                "type": "boolean"
                              },
                              "enable_spoken_emojis": {
                                "description": "The spoken emoji behavior for the call. If ``true``, adds spoken emoji formatting for the request. This will replace spoken emojis with the corresponding Unicode symbols in the final transcript. If ``false``, spoken emojis are not replaced.",
                                "type": "boolean"
                              },
                              "multi_channel_mode": {
                                "description": "Mode for recognizing multi-channel audio.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.RecognitionFeatures.MultiChannelMode"
                              },
                              "diarization_config": {
                                "description": "Configuration to enable speaker diarization and set additional parameters to make diarization better suited for your application. When this is enabled, we send all the words from the beginning of the audio for the top alternative in every consecutive STREAMING responses. This is done in order to improve our speaker tags as our models learn to identify the speakers in the conversation over time. For non-streaming requests, the diarization results will be provided only in the top alternative of the FINAL SpeechRecognitionResult.",
                                "type": "object",
                                "reference": "google.cloud.speech_v2.types.SpeakerDiarizationConfig",
                                "resolved_schema": {
                                  "type": "object",
                                  "properties": {
                                    "min_speaker_count": {
                                      "description": "Required. Minimum number of speakers in the conversation. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.  To fix the number of speakers detected in the audio, set ``min_speaker_count`` = ``max_speaker_count``.",
                                      "type": "integer"
                                    },
                                    "max_speaker_count": {
                                      "description": "Required. Maximum number of speakers in the conversation. Valid values are: 1-6. Must be >= ``min_speaker_count``. This range gives you more flexibility by allowing the system to automatically determine the correct number of speakers.",
                                      "type": "integer"
                                    }
                                  },
                                  "required": [
                                    "min_speaker_count",
                                    "max_speaker_count"
                                  ]
                                }
                              },
                              "max_alternatives": {
                                "description": "Maximum number of recognition hypotheses to be returned. The server may return fewer than ``max_alternatives``. Valid values are ``0``-``30``. A value of ``0`` or ``1`` will return a maximum of one. If omitted, will return a maximum of one.",
                                "type": "integer"
                              }
                            }
                          }
                        },
                        "adaptation": {
                          "description": "Speech adaptation context that weights recognizer predictions for specific words and phrases.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.SpeechAdaptation",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "phrase_sets": {
                                "description": "A list of inline or referenced PhraseSets.",
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "reference": "google.cloud.speech_v2.types.SpeechAdaptation.AdaptationPhraseSet",
                                  "resolved_schema": {
                                    "type": "object",
                                    "properties": {
                                      "phrase_set": {
                                        "description": "The name of an existing PhraseSet resource. The user must have read access to the resource and it must not be deleted.  This field is a member of `oneof`_ ``value``.",
                                        "type": "string"
                                      },
                                      "inline_phrase_set": {
                                        "description": "An inline defined PhraseSet.  This field is a member of `oneof`_ ``value``.",
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.PhraseSet",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "name": {
                                              "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                                              "type": "string"
                                            },
                                            "uid": {
                                              "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                                              "type": "string"
                                            },
                                            "phrases": {
                                              "description": "A list of word and phrases.",
                                              "type": "array",
                                              "items": {
                                                "type": "object",
                                                "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                                                "resolved_schema": {
                                                  "type": "object",
                                                  "properties": {
                                                    "text": {
                                                      "description": "Required. Text input which can be used for prompt or banned phrases.",
                                                      "type": "string"
                                                    },
                                                    "language_code": {
                                                      "description": "Required. Language code of the phrase.",
                                                      "type": "string"
                                                    }
                                                  },
                                                  "required": [
                                                    "text",
                                                    "language_code"
                                                  ]
                                                }
                                              }
                                            },
                                            "boost": {
                                              "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                                              "type": "number"
                                            },
                                            "display_name": {
                                              "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                                              "type": "string"
                                            },
                                            "state": {
                                              "description": "Output only. The PhraseSet lifecycle state.",
                                              "type": "object",
                                              "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                                            },
                                            "create_time": {
                                              "description": "Output only. Creation time.",
                                              "type": "object",
                                              "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                            },
                                            "update_time": {
                                              "description": "Output only. The most recent time this resource was modified.",
                                              "type": "object",
                                              "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                            },
                                            "delete_time": {
                                              "description": "Output only. The time at which this resource was requested for deletion.",
                                              "type": "object",
                                              "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                            },
                                            "expire_time": {
                                              "description": "Output only. The time at which this resource will be purged.",
                                              "type": "object",
                                              "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                            },
                                            "annotations": {
                                              "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                              "type": "object",
                                              "additionalProperties": {
                                                "type": "string"
                                              }
                                            },
                                            "etag": {
                                              "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                              "type": "string"
                                            },
                                            "reconciling": {
                                              "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                                              "type": "boolean"
                                            },
                                            "kms_key_name": {
                                              "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                              "type": "string"
                                            },
                                            "kms_key_version_name": {
                                              "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                              "type": "string"
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              },
                              "custom_classes": {
                                "description": "A list of inline CustomClasses. Existing CustomClass resources can be referenced directly in a PhraseSet.",
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "reference": "google.cloud.speech_v2.types.CustomClass",
                                  "resolved_schema": {
                                    "type": "object",
                                    "properties": {
                                      "name": {
                                        "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                                        "type": "string"
                                      },
                                      "uid": {
                                        "description": "Output only. System-assigned unique identifier for the CustomClass.",
                                        "type": "string"
                                      },
                                      "display_name": {
                                        "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                                        "type": "string"
                                      },
                                      "items": {
                                        "description": "A collection of class items.",
                                        "type": "array",
                                        "items": {
                                          "type": "object",
                                          "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                                          "resolved_schema": {
                                            "type": "object",
                                            "properties": {
                                              "value": {
                                                "description": "The class item's value.",
                                                "type": "string"
                                              }
                                            }
                                          }
                                        }
                                      },
                                      "state": {
                                        "description": "Output only. The CustomClass lifecycle state.",
                                        "type": "object",
                                        "reference": "google.cloud.speech_v2.types.CustomClass.State"
                                      },
                                      "create_time": {
                                        "description": "Output only. Creation time.",
                                        "type": "object",
                                        "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                      },
                                      "update_time": {
                                        "description": "Output only. The most recent time this resource was modified.",
                                        "type": "object",
                                        "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                      },
                                      "delete_time": {
                                        "description": "Output only. The time at which this resource was requested for deletion.",
                                        "type": "object",
                                        "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                      },
                                      "expire_time": {
                                        "description": "Output only. The time at which this resource will be purged.",
                                        "type": "object",
                                        "reference": "google.protobuf.timestamp_pb2.Timestamp"
                                      },
                                      "annotations": {
                                        "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                                        "type": "object",
                                        "additionalProperties": {
                                          "type": "string"
                                        }
                                      },
                                      "etag": {
                                        "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                                        "type": "string"
                                      },
                                      "reconciling": {
                                        "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                                        "type": "boolean"
                                      },
                                      "kms_key_name": {
                                        "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                                        "type": "string"
                                      },
                                      "kms_key_version_name": {
                                        "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                                        "type": "string"
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        },
                        "transcript_normalization": {
                          "description": "Optional. Use transcription normalization to automatically replace parts of the transcript with phrases of your choosing. For StreamingRecognize, this normalization only applies to stable partial transcripts (stability > 0.8) and final transcripts.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.TranscriptNormalization",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "entries": {
                                "description": "A list of replacement entries. We will perform replacement with one entry at a time. For example, the second entry in [\"cat\" => \"dog\", \"mountain cat\" => \"mountain dog\"] will never be applied because we will always process the first entry before it. At most 100 entries.",
                                "type": "array",
                                "items": {
                                  "type": "object",
                                  "reference": "google.cloud.speech_v2.types.TranscriptNormalization.Entry",
                                  "resolved_schema": {
                                    "type": "object",
                                    "properties": {
                                      "role": {
                                        "description": "The granted role, which can be ``READER``, ``WRITER``, or ``OWNER``.",
                                        "type": "string"
                                      },
                                      "group_email": {
                                        "description": "Grants access to a group identified by an email address.",
                                        "type": "string"
                                      },
                                      "user_email": {
                                        "description": "Grants access to a user identified by an email address.",
                                        "type": "string"
                                      },
                                      "domain": {
                                        "description": "Grants access to all members of a domain.",
                                        "type": "string"
                                      },
                                      "special_group": {
                                        "description": "Grants access to special groups. Valid groups are ``PROJECT_OWNERS``, ``PROJECT_READERS``, ``PROJECT_WRITERS`` and ``ALL_AUTHENTICATED_USERS``.",
                                        "type": "string"
                                      },
                                      "view_name": {
                                        "description": "Grants access to a BigQuery View.",
                                        "type": "object",
                                        "reference": "google.cloud.bigquery_logging_v1.types.TableName",
                                        "resolved_schema": {
                                          "type": "object",
                                          "properties": {
                                            "project_id": {
                                              "description": "The project ID.",
                                              "type": "string"
                                            },
                                            "dataset_id": {
                                              "description": "The dataset ID within the project.",
                                              "type": "string"
                                            },
                                            "table_id": {
                                              "description": "The table ID of the table within the dataset.",
                                              "type": "string"
                                            }
                                          }
                                        }
                                      }
                                    }
                                  }
                                }
                              }
                            }
                          }
                        },
                        "translation_config": {
                          "description": "Optional. Optional configuration used to automatically run translation on the given audio to the desired language for supported models.",
                          "type": "object",
                          "reference": "google.cloud.speech_v2.types.TranslationConfig",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "target_language": {
                                "description": "Required. The language code to translate to.",
                                "type": "string"
                              }
                            },
                            "required": [
                              "target_language"
                            ]
                          }
                        }
                      }
                    }
                  },
                  "config_mask": {
                    "description": "The list of fields in [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] that override the values in the [default_recognition_config][google.cloud.speech.v2.Recognizer.default_recognition_config] of the recognizer during this recognition request. If no mask is provided, all non-default valued fields in [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] override the values in the recognizer for this recognition request. If a mask is provided, only the fields listed in the mask override the config in the recognizer for this recognition request. If a wildcard (``*``) is provided, [config][google.cloud.speech.v2.BatchRecognizeFileMetadata.config] completely overrides and replaces the config in the recognizer for this recognition request.",
                    "type": "object",
                    "reference": "google.protobuf.field_mask_pb2.FieldMask"
                  }
                }
              }
            }
          },
          "recognition_output_config": {
            "description": "Configuration options for where to output the transcripts of each file.",
            "reference": "google.cloud.speech_v2.types.RecognitionOutputConfig",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "gcs_output_config": {
                  "description": "If this message is populated, recognition results are written to the provided Google Cloud Storage URI.  This field is a member of `oneof`_ ``output``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.GcsOutputConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "gcs_uri": {
                        "description": "The Cloud Storage uri (a directory) of the output.",
                        "type": "string"
                      },
                      "field_mask": {
                        "description": "Specifies which fields to include in the output documents. Only supports top level document and pages field so it must be in the form of ``{document_field_name}`` or ``pages.{page_field_name}``.",
                        "type": "object",
                        "reference": "google.protobuf.field_mask_pb2.FieldMask"
                      },
                      "sharding_config": {
                        "description": "Specifies the sharding config for the output document.",
                        "type": "object",
                        "reference": "google.cloud.documentai_v1.types.DocumentOutputConfig.GcsOutputConfig.ShardingConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {
                            "pages_per_shard": {
                              "description": "The number of pages per shard.",
                              "type": "integer"
                            },
                            "pages_overlap": {
                              "description": "The number of overlapping pages between consecutive shards.",
                              "type": "integer"
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "inline_response_config": {
                  "description": "If this message is populated, recognition results are provided in the [BatchRecognizeResponse][google.cloud.speech.v2.BatchRecognizeResponse] message of the Operation when completed. This is only supported when calling [BatchRecognize][google.cloud.speech.v2.Speech.BatchRecognize] with just one audio file.  This field is a member of `oneof`_ ``output``.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.InlineOutputConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "output_format_config": {
                  "description": "Optional. Configuration for the format of the results stored to ``output``. If unspecified transcripts will be written in the ``NATIVE`` format only.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.OutputFormatConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "native": {
                        "description": "Configuration for the native output format. If this field is set or if no other output format field is set then transcripts will be written to the sink in the native format.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.NativeOutputFileFormatConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      },
                      "vtt": {
                        "description": "Configuration for the vtt output format. If this field is set then transcripts will be written to the sink in the vtt format.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.VttOutputFileFormatConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      },
                      "srt": {
                        "description": "Configuration for the srt output format. If this field is set then transcripts will be written to the sink in the srt format.",
                        "type": "object",
                        "reference": "google.cloud.speech_v2.types.SrtOutputFileFormatConfig",
                        "resolved_schema": {
                          "type": "object",
                          "properties": {}
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "processing_strategy": {
            "description": "Processing strategy to use for this request.",
            "type": "object",
            "reference": "google.cloud.speech_v2.types.BatchRecognizeRequest.ProcessingStrategy"
          }
        },
        "required": [
          "recognizer"
        ]
      }
    },
    {
      "type": "function",
      "name": "GetConfigRequest",
      "description": "Request message for the\n[GetConfig][google.cloud.speech.v2.Speech.GetConfig] method.\n\nAttributes:\n    name (str):\n        Required. The name of the config to retrieve. There is\n        exactly one config resource per project per location. The\n        expected format is\n        ``projects/{project}/locations/{location}/config``.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the config to retrieve. There is exactly one config resource per project per location. The expected format is ``projects/{project}/locations/{location}/config``.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UpdateConfigRequest",
      "description": "Request message for the\n[UpdateConfig][google.cloud.speech.v2.Speech.UpdateConfig] method.\n\nAttributes:\n    config (google.cloud.speech_v2.types.Config):\n        Required. The config to update.\n\n        The config's ``name`` field is used to identify the config\n        to be updated. The expected format is\n        ``projects/{project}/locations/{location}/config``.\n    update_mask (google.protobuf.field_mask_pb2.FieldMask):\n        The list of fields to be updated.",
      "parameters": {
        "type": "object",
        "properties": {
          "config": {
            "description": "Required. The config to update.  The config's ``name`` field is used to identify the config to be updated. The expected format is ``projects/{project}/locations/{location}/config``.",
            "reference": "google.cloud.speech_v2.types.Config",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "cmek_key_name": {
                  "description": "Required. The Customer Managed Encryption Key (CMEK) used for data encryption. The CMEK name should follow the format of ``projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)``, where the location must match the instance location.",
                  "type": "string"
                }
              },
              "required": [
                "cmek_key_name"
              ]
            }
          },
          "update_mask": {
            "description": "The list of fields to be updated.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          }
        },
        "required": [
          "config"
        ]
      }
    },
    {
      "type": "function",
      "name": "CreateCustomClassRequest",
      "description": "Request message for the\n[CreateCustomClass][google.cloud.speech.v2.Speech.CreateCustomClass]\nmethod.\n\nAttributes:\n    custom_class (google.cloud.speech_v2.types.CustomClass):\n        Required. The CustomClass to create.\n    validate_only (bool):\n        If set, validate the request and preview the\n        CustomClass, but do not actually create it.\n    custom_class_id (str):\n        The ID to use for the CustomClass, which will become the\n        final component of the CustomClass's resource name.\n\n        This value should be 4-63 characters, and valid characters\n        are /[a-z][0-9]-/.\n    parent (str):\n        Required. The project and location where this CustomClass\n        will be created. The expected format is\n        ``projects/{project}/locations/{location}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "custom_class": {
            "description": "Required. The CustomClass to create.",
            "reference": "google.cloud.speech_v2.types.CustomClass",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the CustomClass.",
                  "type": "string"
                },
                "display_name": {
                  "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                  "type": "string"
                },
                "items": {
                  "description": "A collection of class items.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "value": {
                          "description": "The class item's value.",
                          "type": "string"
                        }
                      }
                    }
                  }
                },
                "state": {
                  "description": "Output only. The CustomClass lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.CustomClass.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this resource was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this resource was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this resource will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "annotations": {
                  "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "validate_only": {
            "description": "If set, validate the request and preview the CustomClass, but do not actually create it.",
            "type": "boolean"
          },
          "custom_class_id": {
            "description": "The ID to use for the CustomClass, which will become the final component of the CustomClass's resource name.  This value should be 4-63 characters, and valid characters are /[a-z][0-9]-/.",
            "type": "string"
          },
          "parent": {
            "description": "Required. The project and location where this CustomClass will be created. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          }
        },
        "required": [
          "custom_class",
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "ListCustomClassesRequest",
      "description": "Request message for the\n[ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses]\nmethod.\n\nAttributes:\n    parent (str):\n        Required. The project and location of CustomClass resources\n        to list. The expected format is\n        ``projects/{project}/locations/{location}``.\n    page_size (int):\n        Number of results per requests. A valid page_size ranges\n        from 0 to 100 inclusive. If the page_size is zero or\n        unspecified, a page size of 5 will be chosen. If the page\n        size exceeds 100, it will be coerced down to 100. Note that\n        a call might return fewer results than the requested page\n        size.\n    page_token (str):\n        A page token, received from a previous\n        [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses]\n        call. Provide this to retrieve the subsequent page.\n\n        When paginating, all other parameters provided to\n        [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses]\n        must match the call ",
      "parameters": {
        "type": "object",
        "properties": {
          "parent": {
            "description": "Required. The project and location of CustomClass resources to list. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          },
          "page_size": {
            "description": "Number of results per requests. A valid page_size ranges from 0 to 100 inclusive. If the page_size is zero or unspecified, a page size of 5 will be chosen. If the page size exceeds 100, it will be coerced down to 100. Note that a call might return fewer results than the requested page size.",
            "type": "integer"
          },
          "page_token": {
            "description": "A page token, received from a previous [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] call. Provide this to retrieve the subsequent page.  When paginating, all other parameters provided to [ListCustomClasses][google.cloud.speech.v2.Speech.ListCustomClasses] must match the call that provided the page token.",
            "type": "string"
          },
          "show_deleted": {
            "description": "Whether, or not, to show resources that have been deleted.",
            "type": "boolean"
          }
        },
        "required": [
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "GetCustomClassRequest",
      "description": "Request message for the\n[GetCustomClass][google.cloud.speech.v2.Speech.GetCustomClass]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the CustomClass to retrieve. The\n        expected format is\n        ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the CustomClass to retrieve. The expected format is ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UpdateCustomClassRequest",
      "description": "Request message for the\n[UpdateCustomClass][google.cloud.speech.v2.Speech.UpdateCustomClass]\nmethod.\n\nAttributes:\n    custom_class (google.cloud.speech_v2.types.CustomClass):\n        Required. The CustomClass to update.\n\n        The CustomClass's ``name`` field is used to identify the\n        CustomClass to update. Format:\n        ``projects/{project}/locations/{location}/customClasses/{custom_class}``.\n    update_mask (google.protobuf.field_mask_pb2.FieldMask):\n        The list of fields to be updated. If empty,\n        all fields are considered for update.\n    validate_only (bool):\n        If set, validate the request and preview the\n        updated CustomClass, but do not actually update\n        it.",
      "parameters": {
        "type": "object",
        "properties": {
          "custom_class": {
            "description": "Required. The CustomClass to update.  The CustomClass's ``name`` field is used to identify the CustomClass to update. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
            "reference": "google.cloud.speech_v2.types.CustomClass",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the CustomClass. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the CustomClass.",
                  "type": "string"
                },
                "display_name": {
                  "description": "Optional. User-settable, human-readable name for the CustomClass. Must be 63 characters or less.",
                  "type": "string"
                },
                "items": {
                  "description": "A collection of class items.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.speech_v2.types.CustomClass.ClassItem",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "value": {
                          "description": "The class item's value.",
                          "type": "string"
                        }
                      }
                    }
                  }
                },
                "state": {
                  "description": "Output only. The CustomClass lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.CustomClass.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this resource was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this resource was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this resource will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "annotations": {
                  "description": "Optional. Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this CustomClass is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the CustomClass is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "update_mask": {
            "description": "The list of fields to be updated. If empty, all fields are considered for update.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the updated CustomClass, but do not actually update it.",
            "type": "boolean"
          }
        },
        "required": [
          "custom_class"
        ]
      }
    },
    {
      "type": "function",
      "name": "DeleteCustomClassRequest",
      "description": "Request message for the\n[DeleteCustomClass][google.cloud.speech.v2.Speech.DeleteCustomClass]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the CustomClass to delete. Format:\n        ``projects/{project}/locations/{location}/customClasses/{custom_class}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        deleted CustomClass, but do not actually delete\n        it.\n    allow_missing (bool):\n        If set to true, and the CustomClass is not\n        found, the request will succeed and  be a no-op\n        (no Operation is recorded in this case).\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the CustomClass to delete. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the deleted CustomClass, but do not actually delete it.",
            "type": "boolean"
          },
          "allow_missing": {
            "description": "If set to true, and the CustomClass is not found, the request will succeed and  be a no-op (no Operation is recorded in this case).",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UndeleteCustomClassRequest",
      "description": "Request message for the\n[UndeleteCustomClass][google.cloud.speech.v2.Speech.UndeleteCustomClass]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the CustomClass to undelete. Format:\n        ``projects/{project}/locations/{location}/customClasses/{custom_class}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        undeleted CustomClass, but do not actually\n        undelete it.\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the CustomClass to undelete. Format: ``projects/{project}/locations/{location}/customClasses/{custom_class}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the undeleted CustomClass, but do not actually undelete it.",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "CreatePhraseSetRequest",
      "description": "Request message for the\n[CreatePhraseSet][google.cloud.speech.v2.Speech.CreatePhraseSet]\nmethod.\n\nAttributes:\n    phrase_set (google.cloud.speech_v2.types.PhraseSet):\n        Required. The PhraseSet to create.\n    validate_only (bool):\n        If set, validate the request and preview the\n        PhraseSet, but do not actually create it.\n    phrase_set_id (str):\n        The ID to use for the PhraseSet, which will become the final\n        component of the PhraseSet's resource name.\n\n        This value should be 4-63 characters, and valid characters\n        are /[a-z][0-9]-/.\n    parent (str):\n        Required. The project and location where this PhraseSet will\n        be created. The expected format is\n        ``projects/{project}/locations/{location}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "phrase_set": {
            "description": "Required. The PhraseSet to create.",
            "reference": "google.cloud.speech_v2.types.PhraseSet",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                  "type": "string"
                },
                "phrases": {
                  "description": "A list of word and phrases.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "text": {
                          "description": "Required. Text input which can be used for prompt or banned phrases.",
                          "type": "string"
                        },
                        "language_code": {
                          "description": "Required. Language code of the phrase.",
                          "type": "string"
                        }
                      },
                      "required": [
                        "text",
                        "language_code"
                      ]
                    }
                  }
                },
                "boost": {
                  "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                  "type": "number"
                },
                "display_name": {
                  "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                  "type": "string"
                },
                "state": {
                  "description": "Output only. The PhraseSet lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this resource was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this resource was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this resource will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "annotations": {
                  "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "validate_only": {
            "description": "If set, validate the request and preview the PhraseSet, but do not actually create it.",
            "type": "boolean"
          },
          "phrase_set_id": {
            "description": "The ID to use for the PhraseSet, which will become the final component of the PhraseSet's resource name.  This value should be 4-63 characters, and valid characters are /[a-z][0-9]-/.",
            "type": "string"
          },
          "parent": {
            "description": "Required. The project and location where this PhraseSet will be created. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          }
        },
        "required": [
          "phrase_set",
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "ListPhraseSetsRequest",
      "description": "Request message for the\n[ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets]\nmethod.\n\nAttributes:\n    parent (str):\n        Required. The project and location of PhraseSet resources to\n        list. The expected format is\n        ``projects/{project}/locations/{location}``.\n    page_size (int):\n        The maximum number of PhraseSets to return.\n        The service may return fewer than this value. If\n        unspecified, at most 5 PhraseSets will be\n        returned. The maximum value is 100; values above\n        100 will be coerced to 100.\n    page_token (str):\n        A page token, received from a previous\n        [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets]\n        call. Provide this to retrieve the subsequent page.\n\n        When paginating, all other parameters provided to\n        [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets]\n        must match the call that provided the page token.\n    show_deleted (bool):\n        Whether, or not, to show resources that have\n",
      "parameters": {
        "type": "object",
        "properties": {
          "parent": {
            "description": "Required. The project and location of PhraseSet resources to list. The expected format is ``projects/{project}/locations/{location}``.",
            "type": "string"
          },
          "page_size": {
            "description": "The maximum number of PhraseSets to return. The service may return fewer than this value. If unspecified, at most 5 PhraseSets will be returned. The maximum value is 100; values above 100 will be coerced to 100.",
            "type": "integer"
          },
          "page_token": {
            "description": "A page token, received from a previous [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] call. Provide this to retrieve the subsequent page.  When paginating, all other parameters provided to [ListPhraseSets][google.cloud.speech.v2.Speech.ListPhraseSets] must match the call that provided the page token.",
            "type": "string"
          },
          "show_deleted": {
            "description": "Whether, or not, to show resources that have been deleted.",
            "type": "boolean"
          }
        },
        "required": [
          "parent"
        ]
      }
    },
    {
      "type": "function",
      "name": "GetPhraseSetRequest",
      "description": "Request message for the\n[GetPhraseSet][google.cloud.speech.v2.Speech.GetPhraseSet] method.\n\nAttributes:\n    name (str):\n        Required. The name of the PhraseSet to retrieve. The\n        expected format is\n        ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the PhraseSet to retrieve. The expected format is ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UpdatePhraseSetRequest",
      "description": "Request message for the\n[UpdatePhraseSet][google.cloud.speech.v2.Speech.UpdatePhraseSet]\nmethod.\n\nAttributes:\n    phrase_set (google.cloud.speech_v2.types.PhraseSet):\n        Required. The PhraseSet to update.\n\n        The PhraseSet's ``name`` field is used to identify the\n        PhraseSet to update. Format:\n        ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.\n    update_mask (google.protobuf.field_mask_pb2.FieldMask):\n        The list of fields to update. If empty, all non-default\n        valued fields are considered for update. Use ``*`` to update\n        the entire PhraseSet resource.\n    validate_only (bool):\n        If set, validate the request and preview the\n        updated PhraseSet, but do not actually update\n        it.",
      "parameters": {
        "type": "object",
        "properties": {
          "phrase_set": {
            "description": "Required. The PhraseSet to update.  The PhraseSet's ``name`` field is used to identify the PhraseSet to update. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
            "reference": "google.cloud.speech_v2.types.PhraseSet",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "name": {
                  "description": "Output only. Identifier. The resource name of the PhraseSet. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``.",
                  "type": "string"
                },
                "uid": {
                  "description": "Output only. System-assigned unique identifier for the PhraseSet.",
                  "type": "string"
                },
                "phrases": {
                  "description": "A list of word and phrases.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.speech_v2.types.PhraseSet.Phrase",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "text": {
                          "description": "Required. Text input which can be used for prompt or banned phrases.",
                          "type": "string"
                        },
                        "language_code": {
                          "description": "Required. Language code of the phrase.",
                          "type": "string"
                        }
                      },
                      "required": [
                        "text",
                        "language_code"
                      ]
                    }
                  }
                },
                "boost": {
                  "description": "Hint Boost. Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases. The higher the boost, the higher the chance of false positive recognition as well. Valid ``boost`` values are between 0 (exclusive) and 20. We recommend using a binary search approach to finding the optimal value for your use case as well as adding phrases both with and without boost to your requests.",
                  "type": "number"
                },
                "display_name": {
                  "description": "User-settable, human-readable name for the PhraseSet. Must be 63 characters or less.",
                  "type": "string"
                },
                "state": {
                  "description": "Output only. The PhraseSet lifecycle state.",
                  "type": "object",
                  "reference": "google.cloud.speech_v2.types.PhraseSet.State"
                },
                "create_time": {
                  "description": "Output only. Creation time.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "update_time": {
                  "description": "Output only. The most recent time this resource was modified.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "delete_time": {
                  "description": "Output only. The time at which this resource was requested for deletion.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "expire_time": {
                  "description": "Output only. The time at which this resource will be purged.",
                  "type": "object",
                  "reference": "google.protobuf.timestamp_pb2.Timestamp"
                },
                "annotations": {
                  "description": "Allows users to store small amounts of arbitrary data. Both the key and the value must be 63 characters or less each. At most 100 annotations.",
                  "type": "object",
                  "additionalProperties": {
                    "type": "string"
                  }
                },
                "etag": {
                  "description": "Output only. This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
                  "type": "string"
                },
                "reconciling": {
                  "description": "Output only. Whether or not this PhraseSet is in the process of being updated.",
                  "type": "boolean"
                },
                "kms_key_name": {
                  "description": "Output only. The `KMS key name <https://cloud.google.com/kms/docs/resource-hierarchy#keys>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}``.",
                  "type": "string"
                },
                "kms_key_version_name": {
                  "description": "Output only. The `KMS key version name <https://cloud.google.com/kms/docs/resource-hierarchy#key_versions>`__ with which the PhraseSet is encrypted. The expected format is ``projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{crypto_key}/cryptoKeyVersions/{crypto_key_version}``.",
                  "type": "string"
                }
              }
            }
          },
          "update_mask": {
            "description": "The list of fields to update. If empty, all non-default valued fields are considered for update. Use ``*`` to update the entire PhraseSet resource.",
            "type": "object",
            "reference": "google.protobuf.field_mask_pb2.FieldMask"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the updated PhraseSet, but do not actually update it.",
            "type": "boolean"
          }
        },
        "required": [
          "phrase_set"
        ]
      }
    },
    {
      "type": "function",
      "name": "DeletePhraseSetRequest",
      "description": "Request message for the\n[DeletePhraseSet][google.cloud.speech.v2.Speech.DeletePhraseSet]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the PhraseSet to delete. Format:\n        ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        deleted PhraseSet, but do not actually delete\n        it.\n    allow_missing (bool):\n        If set to true, and the PhraseSet is not\n        found, the request will succeed and  be a no-op\n        (no Operation is recorded in this case).\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the PhraseSet to delete. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the deleted PhraseSet, but do not actually delete it.",
            "type": "boolean"
          },
          "allow_missing": {
            "description": "If set to true, and the PhraseSet is not found, the request will succeed and  be a no-op (no Operation is recorded in this case).",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    },
    {
      "type": "function",
      "name": "UndeletePhraseSetRequest",
      "description": "Request message for the\n[UndeletePhraseSet][google.cloud.speech.v2.Speech.UndeletePhraseSet]\nmethod.\n\nAttributes:\n    name (str):\n        Required. The name of the PhraseSet to undelete. Format:\n        ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``\n    validate_only (bool):\n        If set, validate the request and preview the\n        undeleted PhraseSet, but do not actually\n        undelete it.\n    etag (str):\n        This checksum is computed by the server based\n        on the value of other fields. This may be sent\n        on update, undelete, and delete requests to\n        ensure the client has an up-to-date value before\n        proceeding.",
      "parameters": {
        "type": "object",
        "properties": {
          "name": {
            "description": "Required. The name of the PhraseSet to undelete. Format: ``projects/{project}/locations/{location}/phraseSets/{phrase_set}``",
            "type": "string"
          },
          "validate_only": {
            "description": "If set, validate the request and preview the undeleted PhraseSet, but do not actually undelete it.",
            "type": "boolean"
          },
          "etag": {
            "description": "This checksum is computed by the server based on the value of other fields. This may be sent on update, undelete, and delete requests to ensure the client has an up-to-date value before proceeding.",
            "type": "string"
          }
        },
        "required": [
          "name"
        ]
      }
    }
  ]
}
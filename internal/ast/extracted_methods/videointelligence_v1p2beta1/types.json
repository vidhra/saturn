{
  "/Users/prashanthvarma/Saturn/internal/ast/google-cloud-python/packages/google-cloud-videointelligence/google/cloud/videointelligence_v1p2beta1/types/video_intelligence.py": [
    {
      "type": "function",
      "name": "AnnotateVideoRequest",
      "description": "Video annotation request.\n\nAttributes:\n    input_uri (str):\n        Input video location. Currently, only `Google Cloud\n        Storage <https://cloud.google.com/storage/>`__ URIs are\n        supported, which must be specified in the following format:\n        ``gs://bucket-id/object-id`` (other URI formats return\n        [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]).\n        For more information, see `Request\n        URIs <https://cloud.google.com/storage/docs/request-endpoints>`__.\n        A video URI may include wildcards in ``object-id``, and thus\n        identify multiple videos. Supported wildcards: '*' to match\n        0 or more characters; '?' to match 1 character. If unset,\n        the input video should be embedded in the request as\n        ``input_content``. If set, ``input_content`` should be\n        unset.\n    input_content (bytes):\n        The video data bytes. If unset, the input video(s) should be\n        specified via ``input_uri``. If set, ``input_uri`` should be\n     ",
      "parameters": {
        "type": "object",
        "properties": {
          "input_uri": {
            "description": "Input video location. Currently, only `Google Cloud Storage <https://cloud.google.com/storage/>`__ URIs are supported, which must be specified in the following format: ``gs://bucket-id/object-id`` (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see `Request URIs <https://cloud.google.com/storage/docs/request-endpoints>`__. A video URI may include wildcards in ``object-id``, and thus identify multiple videos. Supported wildcards: '*' to match 0 or more characters; '?' to match 1 character. If unset, the input video should be embedded in the request as ``input_content``. If set, ``input_content`` should be unset.",
            "type": "string"
          },
          "input_content": {
            "description": "The video data bytes. If unset, the input video(s) should be specified via ``input_uri``. If set, ``input_uri`` should be unset.",
            "type": "object",
            "reference": "bytes"
          },
          "features": {
            "description": "Required. Requested video annotation features.",
            "type": "array",
            "items": {
              "reference": "google.cloud.videointelligence_v1p2beta1.types.Feature",
              "resolved_schema": {
                "type": "object",
                "properties": {
                  "type_": {
                    "description": "The type of the feature that enabled for fulfillment.",
                    "type": "object",
                    "reference": "google.cloud.dialogflow_v2.types.Fulfillment.Feature.Type"
                  }
                }
              }
            }
          },
          "video_context": {
            "description": "Additional video context and/or feature-specific parameters.",
            "reference": "google.cloud.videointelligence_v1p2beta1.types.VideoContext",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "segments": {
                  "description": "Video segments to annotate. The segments may overlap and are not required to be contiguous or span the whole video. If unspecified, each video is treated as a single segment.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.videointelligence_v1beta2.types.VideoSegment",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "start_time_offset": {
                          "description": "Time-offset, relative to the beginning of the video, corresponding to the start of the segment (inclusive).",
                          "type": "object",
                          "reference": "google.protobuf.duration_pb2.Duration",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "nanos": {
                                "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                "type": "integer"
                              },
                              "seconds": {
                                "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                "type": "integer"
                              }
                            }
                          }
                        },
                        "end_time_offset": {
                          "description": "Time-offset, relative to the beginning of the video, corresponding to the end of the segment (inclusive).",
                          "type": "object",
                          "reference": "google.protobuf.duration_pb2.Duration",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "nanos": {
                                "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                "type": "integer"
                              },
                              "seconds": {
                                "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                "type": "integer"
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "label_detection_config": {
                  "description": "Config for LABEL_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.LabelDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "label_detection_mode": {
                        "description": "What labels should be detected with LABEL_DETECTION, in addition to video-level labels or segment-level labels. If unspecified, defaults to ``SHOT_MODE``.",
                        "type": "object",
                        "reference": "google.cloud.videointelligence_v1beta2.types.LabelDetectionMode"
                      },
                      "stationary_camera": {
                        "description": "Whether the video has been shot from a stationary (i.e. non-moving) camera. When set to true, might improve detection accuracy for moving objects. Should be used with ``SHOT_AND_FRAME_MODE`` enabled.",
                        "type": "boolean"
                      },
                      "model": {
                        "description": "Model to use for label detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "shot_change_detection_config": {
                  "description": "Config for SHOT_CHANGE_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.ShotChangeDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for shot change detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "explicit_content_detection_config": {
                  "description": "Config for EXPLICIT_CONTENT_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.ExplicitContentDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for explicit content detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "face_detection_config": {
                  "description": "Config for FACE_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.FaceDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for face detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      },
                      "include_bounding_boxes": {
                        "description": "Whether bounding boxes be included in the face annotation output.",
                        "type": "boolean"
                      }
                    }
                  }
                }
              }
            }
          },
          "output_uri": {
            "description": "Optional. Location where the output (in JSON format) should be stored. Currently, only `Google Cloud Storage <https://cloud.google.com/storage/>`__ URIs are supported, which must be specified in the following format: ``gs://bucket-id/object-id`` (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see `Request URIs <https://cloud.google.com/storage/docs/request-endpoints>`__.",
            "type": "string"
          },
          "location_id": {
            "description": "Optional. Cloud region where annotation should take place. Supported cloud regions: ``us-east1``, ``us-west1``, ``europe-west1``, ``asia-east1``. If no region is specified, a region will be determined based on video file location.",
            "type": "string"
          }
        },
        "required": [
          "features"
        ]
      }
    }
  ]
}
{
  "/Users/prashanthvarma/Saturn/internal/ast/google-cloud-python/packages/google-cloud-videointelligence/google/cloud/videointelligence_v1p3beta1/types/video_intelligence.py": [
    {
      "type": "function",
      "name": "AnnotateVideoRequest",
      "description": "Video annotation request.\n\nAttributes:\n    input_uri (str):\n        Input video location. Currently, only `Cloud\n        Storage <https://cloud.google.com/storage/>`__ URIs are\n        supported. URIs must be specified in the following format:\n        ``gs://bucket-id/object-id`` (other URI formats return\n        [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]).\n        For more information, see `Request\n        URIs <https://cloud.google.com/storage/docs/request-endpoints>`__.\n        To identify multiple videos, a video URI may include\n        wildcards in the ``object-id``. Supported wildcards: '*' to\n        match 0 or more characters; '?' to match 1 character. If\n        unset, the input video should be embedded in the request as\n        ``input_content``. If set, ``input_content`` must be unset.\n    input_content (bytes):\n        The video data bytes. If unset, the input video(s) should be\n        specified via the ``input_uri``. If set, ``input_uri`` must\n        be unset.\n    feat",
      "parameters": {
        "type": "object",
        "properties": {
          "input_uri": {
            "description": "Input video location. Currently, only `Cloud Storage <https://cloud.google.com/storage/>`__ URIs are supported. URIs must be specified in the following format: ``gs://bucket-id/object-id`` (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see `Request URIs <https://cloud.google.com/storage/docs/request-endpoints>`__. To identify multiple videos, a video URI may include wildcards in the ``object-id``. Supported wildcards: '*' to match 0 or more characters; '?' to match 1 character. If unset, the input video should be embedded in the request as ``input_content``. If set, ``input_content`` must be unset.",
            "type": "string"
          },
          "input_content": {
            "description": "The video data bytes. If unset, the input video(s) should be specified via the ``input_uri``. If set, ``input_uri`` must be unset.",
            "type": "object",
            "reference": "bytes"
          },
          "features": {
            "description": "Required. Requested video annotation features.",
            "type": "array",
            "items": {
              "reference": "google.cloud.videointelligence_v1p3beta1.types.Feature",
              "resolved_schema": {
                "type": "object",
                "properties": {
                  "type_": {
                    "description": "The type of the feature that enabled for fulfillment.",
                    "type": "object",
                    "reference": "google.cloud.dialogflow_v2.types.Fulfillment.Feature.Type"
                  }
                }
              }
            }
          },
          "video_context": {
            "description": "Additional video context and/or feature-specific parameters.",
            "reference": "google.cloud.videointelligence_v1p3beta1.types.VideoContext",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "segments": {
                  "description": "Video segments to annotate. The segments may overlap and are not required to be contiguous or span the whole video. If unspecified, each video is treated as a single segment.",
                  "type": "array",
                  "items": {
                    "type": "object",
                    "reference": "google.cloud.videointelligence_v1beta2.types.VideoSegment",
                    "resolved_schema": {
                      "type": "object",
                      "properties": {
                        "start_time_offset": {
                          "description": "Time-offset, relative to the beginning of the video, corresponding to the start of the segment (inclusive).",
                          "type": "object",
                          "reference": "google.protobuf.duration_pb2.Duration",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "nanos": {
                                "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                "type": "integer"
                              },
                              "seconds": {
                                "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                "type": "integer"
                              }
                            }
                          }
                        },
                        "end_time_offset": {
                          "description": "Time-offset, relative to the beginning of the video, corresponding to the end of the segment (inclusive).",
                          "type": "object",
                          "reference": "google.protobuf.duration_pb2.Duration",
                          "resolved_schema": {
                            "type": "object",
                            "properties": {
                              "nanos": {
                                "description": "Span of time that's a fraction of a second at nanosecond resolution. Durations less than one second are represented with a 0 ``seconds`` field and a positive ``nanos`` field. Must be from 0 to 999,999,999 inclusive.  This field is a member of `oneof`_ ``_nanos``.",
                                "type": "integer"
                              },
                              "seconds": {
                                "description": "Span of time at a resolution of a second. Must be from 0 to 315,576,000,000 inclusive. Note: these bounds are computed from: 60 sec/min \\* 60 min/hr \\* 24 hr/day \\* 365.25 days/year \\* 10000 years  This field is a member of `oneof`_ ``_seconds``.",
                                "type": "integer"
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                },
                "label_detection_config": {
                  "description": "Config for LABEL_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.LabelDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "label_detection_mode": {
                        "description": "What labels should be detected with LABEL_DETECTION, in addition to video-level labels or segment-level labels. If unspecified, defaults to ``SHOT_MODE``.",
                        "type": "object",
                        "reference": "google.cloud.videointelligence_v1beta2.types.LabelDetectionMode"
                      },
                      "stationary_camera": {
                        "description": "Whether the video has been shot from a stationary (i.e. non-moving) camera. When set to true, might improve detection accuracy for moving objects. Should be used with ``SHOT_AND_FRAME_MODE`` enabled.",
                        "type": "boolean"
                      },
                      "model": {
                        "description": "Model to use for label detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "shot_change_detection_config": {
                  "description": "Config for SHOT_CHANGE_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.ShotChangeDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for shot change detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "explicit_content_detection_config": {
                  "description": "Config for EXPLICIT_CONTENT_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.ExplicitContentDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for explicit content detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      }
                    }
                  }
                },
                "face_detection_config": {
                  "description": "Config for FACE_DETECTION.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1beta2.types.FaceDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model": {
                        "description": "Model to use for face detection. Supported values: \"builtin/stable\" (the default if unset) and \"builtin/latest\".",
                        "type": "string"
                      },
                      "include_bounding_boxes": {
                        "description": "Whether bounding boxes be included in the face annotation output.",
                        "type": "boolean"
                      }
                    }
                  }
                }
              }
            }
          },
          "output_uri": {
            "description": "Optional. Location where the output (in JSON format) should be stored. Currently, only `Cloud Storage <https://cloud.google.com/storage/>`__ URIs are supported. These must be specified in the following format: ``gs://bucket-id/object-id`` (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see `Request URIs <https://cloud.google.com/storage/docs/request-endpoints>`__.",
            "type": "string"
          },
          "location_id": {
            "description": "Optional. Cloud region where annotation should take place. Supported cloud regions are: ``us-east1``, ``us-west1``, ``europe-west1``, ``asia-east1``. If no region is specified, the region will be determined based on video file location.",
            "type": "string"
          }
        },
        "required": [
          "features"
        ]
      }
    },
    {
      "type": "function",
      "name": "StreamingAnnotateVideoRequest",
      "description": "The top-level message sent by the client for the\n``StreamingAnnotateVideo`` method. Multiple\n``StreamingAnnotateVideoRequest`` messages are sent. The first\nmessage must only contain a ``StreamingVideoConfig`` message. All\nsubsequent messages must only contain ``input_content`` data.\n\nThis message has `oneof`_ fields (mutually exclusive fields).\nFor each oneof, at most one member field can be set at the same time.\nSetting any member of the oneof automatically clears all other\nmembers.\n\n.. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields\n\nAttributes:\n    video_config (google.cloud.videointelligence_v1p3beta1.types.StreamingVideoConfig):\n        Provides information to the annotator, specifing how to\n        process the request. The first\n        ``AnnotateStreamingVideoRequest`` message must only contain\n        a ``video_config`` message.\n\n        This field is a member of `oneof`_ ``streaming_request``.\n    input_content (bytes):\n        The video data to",
      "parameters": {
        "type": "object",
        "properties": {
          "video_config": {
            "description": "Provides information to the annotator, specifing how to process the request. The first ``AnnotateStreamingVideoRequest`` message must only contain a ``video_config`` message.  This field is a member of `oneof`_ ``streaming_request``.",
            "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingVideoConfig",
            "resolved_schema": {
              "type": "object",
              "properties": {
                "shot_change_detection_config": {
                  "description": "Config for STREAMING_SHOT_CHANGE_DETECTION.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingShotChangeDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "label_detection_config": {
                  "description": "Config for STREAMING_LABEL_DETECTION.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingLabelDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "stationary_camera": {
                        "description": "Whether the video has been captured from a stationary (i.e. non-moving) camera. When set to true, might improve detection accuracy for moving objects. Default: false.",
                        "type": "boolean"
                      }
                    }
                  }
                },
                "explicit_content_detection_config": {
                  "description": "Config for STREAMING_EXPLICIT_CONTENT_DETECTION.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingExplicitContentDetectionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "object_tracking_config": {
                  "description": "Config for STREAMING_OBJECT_TRACKING.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingObjectTrackingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {}
                  }
                },
                "automl_action_recognition_config": {
                  "description": "Config for STREAMING_AUTOML_ACTION_RECOGNITION.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingAutomlActionRecognitionConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model_name": {
                        "description": "Resource name of AutoML model. Format: ``projects/{project_id}/locations/{location_id}/models/{model_id}``",
                        "type": "string"
                      }
                    }
                  }
                },
                "automl_classification_config": {
                  "description": "Config for STREAMING_AUTOML_CLASSIFICATION.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingAutomlClassificationConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model_name": {
                        "description": "Resource name of AutoML model. Format: ``projects/{project_number}/locations/{location_id}/models/{model_id}``",
                        "type": "string"
                      }
                    }
                  }
                },
                "automl_object_tracking_config": {
                  "description": "Config for STREAMING_AUTOML_OBJECT_TRACKING.  This field is a member of `oneof`_ ``streaming_config``.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingAutomlObjectTrackingConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "model_name": {
                        "description": "Resource name of AutoML model. Format: ``projects/{project_id}/locations/{location_id}/models/{model_id}``",
                        "type": "string"
                      }
                    }
                  }
                },
                "feature": {
                  "description": "Requested annotation feature.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingFeature"
                },
                "storage_config": {
                  "description": "Streaming storage option. By default: storage is disabled.",
                  "type": "object",
                  "reference": "google.cloud.videointelligence_v1p3beta1.types.StreamingStorageConfig",
                  "resolved_schema": {
                    "type": "object",
                    "properties": {
                      "enable_storage_annotation_result": {
                        "description": "Enable streaming storage. Default: false.",
                        "type": "boolean"
                      },
                      "annotation_result_storage_directory": {
                        "description": "Cloud Storage URI to store all annotation results for one client. Client should specify this field as the top-level storage directory. Annotation results of different sessions will be put into different sub-directories denoted by project_name and session_id. All sub-directories will be auto generated by program and will be made accessible to client in response proto. URIs must be specified in the following format: ``gs://bucket-id/object-id`` ``bucket-id`` should be a valid Cloud Storage bucket created by client and bucket permission shall also be configured properly. ``object-id`` can be arbitrary string that make sense to client. Other URI formats will return error and cause Cloud Storage write failure.",
                        "type": "string"
                      }
                    }
                  }
                }
              }
            }
          },
          "input_content": {
            "description": "The video data to be annotated. Chunks of video data are sequentially sent in ``StreamingAnnotateVideoRequest`` messages. Except the initial ``StreamingAnnotateVideoRequest`` message containing only ``video_config``, all subsequent ``AnnotateStreamingVideoRequest`` messages must only contain ``input_content`` field. Note: as with all bytes fields, protobuffers use a pure binary representation (not base64).  This field is a member of `oneof`_ ``streaming_request``.",
            "type": "object",
            "reference": "bytes"
          }
        }
      }
    }
  ]
}